{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hope you are having a good week. Just checking in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>K..give back my thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Am also doing in cbe only. But have to pay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary 4 STAR Ibiza Holiday or å£10,000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail: Dear Dave this is your final notice to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>You are a great role model. You are giving so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Awesome, I remember the last time we got someb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>spam</td>\n",
       "      <td>If you don't, your prize will go to another cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>spam</td>\n",
       "      <td>SMS. ac JSco: Energy is high, but u may not kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Shall call now dear having food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5559 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type                                               Text\n",
       "0      ham  Hope you are having a good week. Just checking in\n",
       "1      ham                            K..give back my thanks.\n",
       "2      ham        Am also doing in cbe only. But have to pay.\n",
       "3     spam  complimentary 4 STAR Ibiza Holiday or å£10,000...\n",
       "4     spam  okmail: Dear Dave this is your final notice to...\n",
       "...    ...                                                ...\n",
       "5554   ham  You are a great role model. You are giving so ...\n",
       "5555   ham  Awesome, I remember the last time we got someb...\n",
       "5556  spam  If you don't, your prize will go to another cu...\n",
       "5557  spam  SMS. ac JSco: Energy is high, but u may not kn...\n",
       "5558   ham                    Shall call now dear having food\n",
       "\n",
       "[5559 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "raw_df = pd.read_csv('C:\\\\Users\\\\kp\\\\Pictures\\\\Assignments\\\\Naive Bayes\\\\sms_raw_NB.csv',header=0,encoding='latin-1')\n",
    "raw_df.columns=['Type','Text']\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>hope good week  check</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>kgive back thank</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>also cbe  pay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary  star ibiza holiday  cash need u...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail  dear dave final notice collect  teneri...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5151</th>\n",
       "      <td>ham</td>\n",
       "      <td>great role model  give much really wish day mi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5152</th>\n",
       "      <td>ham</td>\n",
       "      <td>awesome  remember last time get somebody high ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>spam</td>\n",
       "      <td>nt  prize go another customer   c wwwtcbiz  pm...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>spam</td>\n",
       "      <td>sms  ac jsco  energy high  u may know channel ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>ham</td>\n",
       "      <td>shall call dear food</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type                                               Text  Class_Code\n",
       "0      ham                              hope good week  check           1\n",
       "1      ham                                  kgive back thank            1\n",
       "2      ham                                     also cbe  pay            1\n",
       "3     spam  complimentary  star ibiza holiday  cash need u...          -1\n",
       "4     spam  okmail  dear dave final notice collect  teneri...          -1\n",
       "...    ...                                                ...         ...\n",
       "5151   ham  great role model  give much really wish day mi...           1\n",
       "5152   ham  awesome  remember last time get somebody high ...           1\n",
       "5153  spam  nt  prize go another customer   c wwwtcbiz  pm...          -1\n",
       "5154  spam  sms  ac jsco  energy high  u may know channel ...          -1\n",
       "5155   ham                               shall call dear food           1\n",
       "\n",
       "[5156 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Text'] = raw_df['Text'].astype('str')\n",
    "raw_df['Type'] = raw_df['Type'].astype('str')\n",
    "\n",
    "raw_df = raw_df.fillna(0)\n",
    "raw_df.drop(raw_df[raw_df['Text'] == 0].index, axis=0, inplace=True)\n",
    "raw_df.drop(raw_df[raw_df['Type'] == 0].index, axis=0, inplace=True)\n",
    "raw_df.drop_duplicates(subset='Text', keep='first', inplace=True)\n",
    "\n",
    "raw_df=raw_df.reset_index(drop=True)\n",
    "\n",
    "raw_df.Text = raw_df.Text.str.lower()\n",
    "\n",
    "raw_df['Text'] = raw_df['Text'].str.replace(\"'s'\", \"\")\n",
    "\n",
    "raw_df[\"Text\"] = raw_df['Text'].apply(lambda record: word_tokenize(record))\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "raw_df['Text'] = raw_df['Text'].apply(lambda record: [word for word in record if word not in stop_words])\n",
    "    \n",
    "def apply_lemmatization(string_list):\n",
    "\n",
    "    lem = WordNetLemmatizer()\n",
    "    list = []\n",
    "\n",
    "    for word in string_list:\n",
    "        list.append(lem.lemmatize(word, \"v\"))\n",
    "\n",
    "    return list\n",
    "\n",
    "raw_df['Text'] = raw_df['Text'].apply(apply_lemmatization)\n",
    "\n",
    "raw_df.Text = raw_df.Text.apply(lambda record: \" \".join(record))\n",
    "\n",
    "raw_df[\"Text\"] = raw_df['Text'].apply(lambda x: re.sub('[^A-Za-z\" \"]+', \"\", x))\n",
    "\n",
    "class_codes = {'ham': 1, 'spam': -1}\n",
    "raw_df['Class_Code'] = raw_df['Type']\n",
    "raw_df = raw_df.replace({'Class_Code': class_codes})\n",
    "cleaned_df=raw_df\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_df['Text'],\n",
    "                                                    cleaned_df['Class_Code'], test_size=0.15,random_state=8)\n",
    "\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                                ngram_range=(1, 2),\n",
    "                                stop_words=None,\n",
    "                                lowercase=False,\n",
    "                                max_df=1.0,\n",
    "                                min_df=10,\n",
    "                                max_features=700,\n",
    "                                norm='l2',\n",
    "                                sublinear_tf=True)\n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "class_labels_train = y_train\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "class_labels_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Gaussian Naive Bayes model accuracy(in %): 71.57622739018088\n",
      "Train Accuracy of Gaussian Naive Bayes model accuracy(in %): 75.03423094477407\n"
     ]
    }
   ],
   "source": [
    "gaussian_nbc = GaussianNB()\n",
    "pred_gaussian = gaussian_nbc.fit(features_train,class_labels_train).predict(features_test)\n",
    "pred_gaussian_train=gaussian_nbc.predict(features_train)\n",
    "confusion_matrix(y_test,pred_gaussian)\n",
    "print (\"Test Accuracy of Gaussian Naive Bayes model accuracy(in %):\", accuracy_score(y_test, pred_gaussian)*100)\n",
    "print (\"Train Accuracy of Gaussian Naive Bayes model accuracy(in %):\", accuracy_score(y_train, pred_gaussian_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of MultiNomial Naive Bayes model accuracy(in %): 97.1576227390181\n",
      "Train Accuracy of MultiNomial Naive Bayes model accuracy(in %): 97.740757644911\n"
     ]
    }
   ],
   "source": [
    "multinomial_nbc = MultinomialNB()\n",
    "pred_multinomial = multinomial_nbc.fit(features_train,class_labels_train).predict(features_test)\n",
    "pred_multinomial_train=multinomial_nbc.predict(features_train)\n",
    "confusion_matrix(y_test,pred_multinomial)\n",
    "print (\"Test Accuracy of MultiNomial Naive Bayes model accuracy(in %):\", accuracy_score(y_test, pred_multinomial)*100)\n",
    "print (\"Train Accuracy of MultiNomial Naive Bayes model accuracy(in %):\", accuracy_score(y_train, pred_multinomial_train)*100)\n",
    "#MultiNomial Naive Bayes Classifier is prebable Classifier when the features Vectors are Documents or for Documents Classificatio Problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
